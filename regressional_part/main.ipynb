{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127826f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, torchaudio, pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bundle = torchaudio.pipelines.WAV2VEC2_BASE\n",
    "wav2vec_model = bundle.get_model().to(device).eval()\n",
    "\n",
    "TRAIN_AUDIO_DIR = \"../dataset/audios_train\"\n",
    "TEST_AUDIO_DIR = \"../dataset/audios_test\"\n",
    "TRAIN_CSV_PATH = \"../dataset/train.csv\"\n",
    "TEST_CSV_PATH = \"../dataset/test.csv\"\n",
    "\n",
    "BEST_LEARNING_RATE = 0.0004956131596941485\n",
    "BEST_BATCH_SIZE = 32\n",
    "BEST_EPOCHS = 80\n",
    "BEST_DROPOUT_RATE = 0.3183369837123387\n",
    "BEST_NUM_HIDDEN_LAYERS = 2\n",
    "BEST_HIDDEN_DIM = 128\n",
    "FINAL_MODEL_PATH = \"final_regression_model_submit.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce35fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, csv_path, audio_dir, is_test=False):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        waveform, sr = torchaudio.load(os.path.join(self.audio_dir, row['filename']))\n",
    "        if sr != bundle.sample_rate:\n",
    "            waveform = torchaudio.transforms.Resample(sr, bundle.sample_rate)(waveform)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        waveform = waveform.to(device)\n",
    "\n",
    "        if self.is_test:\n",
    "            return waveform, row['filename']\n",
    "        else:\n",
    "            label = torch.tensor(float(row['label']), dtype=torch.float32).to(device)\n",
    "            return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9714b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class RegressionHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_hidden_layers, hidden_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "        layers = [nn.LayerNorm(input_dim)]\n",
    "        current_dim = input_dim\n",
    "        for _ in range(num_hidden_layers):\n",
    "            layers.extend([\n",
    "                nn.Linear(current_dim, hidden_dim),\n",
    "                Swish(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            current_dim = hidden_dim\n",
    "        layers.append(nn.Linear(current_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b61ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(waveform):\n",
    "    with torch.no_grad():\n",
    "        if waveform.dim() == 3:\n",
    "            waveform = waveform.squeeze(1)\n",
    "        features, _ = wav2vec_model.extract_features(waveform)\n",
    "        selected_layers = features[-3:]\n",
    "        stat_feats = [torch.cat([layer.mean(1), layer.std(1)], dim=1) for layer in selected_layers]\n",
    "        return torch.cat(stat_feats, dim=1)\n",
    "\n",
    "def collate_fn_train(batch):\n",
    "    waveforms = [x[0] for x in batch]\n",
    "    labels = torch.stack([x[1] for x in batch])\n",
    "    return waveforms, labels\n",
    "\n",
    "def collate_fn_test(batch):\n",
    "    waveforms = [x[0] for x in batch]\n",
    "    filenames = [x[1] for x in batch]\n",
    "    return waveforms, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c007b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final():\n",
    "    train_dataset = AudioDataset(TRAIN_CSV_PATH, TRAIN_AUDIO_DIR, is_test=False)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BEST_BATCH_SIZE, shuffle=True, collate_fn=collate_fn_train)\n",
    "\n",
    "    input_dim = extract_features(torch.randn(1, 16000).to(device)).shape[1]\n",
    "    final_model = RegressionHead(input_dim, BEST_NUM_HIDDEN_LAYERS, BEST_HIDDEN_DIM, BEST_DROPOUT_RATE).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(final_model.parameters(), lr=BEST_LEARNING_RATE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    print(\"Starting final training with best hyperparameters...\")\n",
    "    for epoch in range(BEST_EPOCHS):\n",
    "        final_model.train()\n",
    "        total_loss = 0.0\n",
    "        for waveforms, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{BEST_EPOCHS} [Train]\"):\n",
    "            feats = torch.cat([extract_features(wf.unsqueeze(0)).cpu() for wf in waveforms], dim=0).to(device)\n",
    "            preds = final_model(feats)\n",
    "            loss = criterion(preds, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{BEST_EPOCHS}: Train Loss={avg_train_loss:.4f}\")\n",
    "\n",
    "    torch.save(final_model.state_dict(), FINAL_MODEL_PATH)\n",
    "    print(f\"✔️ Final model saved to {FINAL_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a430e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final():\n",
    "    if not os.path.exists(FINAL_MODEL_PATH):\n",
    "        print(f\"Error: Final model not found at {FINAL_MODEL_PATH}. Please run train_final() first.\")\n",
    "        return\n",
    "\n",
    "    test_dataset = AudioDataset(TEST_CSV_PATH, TEST_AUDIO_DIR, is_test=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BEST_BATCH_SIZE, shuffle=False, collate_fn=collate_fn_test)\n",
    "\n",
    "    input_dim = extract_features(torch.randn(1, 16000).to(device)).shape[1]\n",
    "    final_model = RegressionHead(input_dim, BEST_NUM_HIDDEN_LAYERS, BEST_HIDDEN_DIM, BEST_DROPOUT_RATE).to(device)\n",
    "    final_model.load_state_dict(torch.load(FINAL_MODEL_PATH))\n",
    "    final_model.eval()\n",
    "\n",
    "    print(\"Starting final evaluation on the test set...\")\n",
    "    all_preds = []\n",
    "    all_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for waveforms, filenames in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            feats = torch.cat([extract_features(wf.unsqueeze(0)).cpu() for wf in waveforms], dim=0).to(device)\n",
    "            preds = final_model(feats)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_filenames.extend(filenames)\n",
    "\n",
    "    output_df = pd.DataFrame({\n",
    "        'filename': all_filenames,\n",
    "        'label': all_preds\n",
    "    })\n",
    "    output_df.iloc[:, 1] = output_df.iloc[:, 1].apply(lambda x: round(x * 2) / 2)\n",
    "    output_df.to_csv(\"test_predictions_regression_submit.csv\", index=False)\n",
    "    print(\"✔️ Predictions saved to test_predictions_regression_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42350ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting final training with best hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/80 [Train]: 100%|██████████| 14/14 [01:47<00:00,  7.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80: Train Loss=4.1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/80 [Train]: 100%|██████████| 14/14 [02:02<00:00,  8.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/80: Train Loss=1.6997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/80 [Train]: 100%|██████████| 14/14 [02:05<00:00,  8.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/80: Train Loss=1.6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/80 [Train]: 100%|██████████| 14/14 [02:06<00:00,  9.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/80: Train Loss=1.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/80 [Train]: 100%|██████████| 14/14 [02:06<00:00,  9.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/80: Train Loss=1.2283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/80 [Train]: 100%|██████████| 14/14 [02:05<00:00,  8.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/80: Train Loss=1.1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/80 [Train]: 100%|██████████| 14/14 [02:06<00:00,  9.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/80: Train Loss=1.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/80 [Train]: 100%|██████████| 14/14 [02:06<00:00,  9.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/80: Train Loss=1.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/80 [Train]: 100%|██████████| 14/14 [02:06<00:00,  9.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/80: Train Loss=0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/80 [Train]: 100%|██████████| 14/14 [02:06<00:00,  9.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/80: Train Loss=0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/80 [Train]: 100%|██████████| 14/14 [02:06<00:00,  9.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/80: Train Loss=0.8853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/80 [Train]: 100%|██████████| 14/14 [02:06<00:00,  9.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/80: Train Loss=0.8831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/80 [Train]:  64%|██████▍   | 9/14 [01:15<00:43,  8.68s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_final()\n",
    "    evaluate_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e24bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of predicted labels\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(output_df['label'], bins=[1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5], edgecolor='black', rwidth=0.9)\n",
    "plt.xticks([1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0])\n",
    "plt.xlabel(\"Predicted MOS Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Predicted Grammar Scores\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff21991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by filename (or any order) for trendline visualization\n",
    "df_sorted = output_df.sort_values('filename')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(df_sorted['label'].values, marker='o', linestyle='-', color='teal')\n",
    "plt.xlabel(\"Test Sample Index (sorted by filename)\")\n",
    "plt.ylabel(\"Predicted MOS Score\")\n",
    "plt.title(\"Trend of Predicted Grammar Scores\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77674f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a statistical summary\n",
    "plt.figure(figsize=(4, 6))\n",
    "plt.boxplot(output_df['label'], vert=True, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
    "plt.ylabel(\"Predicted MOS Score\")\n",
    "plt.title(\"Boxplot of Predicted Grammar Scores\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
